# ğŸ¬ Movie & TV Show Data Cleaning Pipeline

A professional data preprocessing and cleaning pipeline specifically designed for movie and TV show datasets. This automated pipeline transforms raw, messy entertainment data into clean, analysis-ready datasets suitable for machine learning and data analysis.

## ğŸ“Š Project Overview

This project provides a robust data cleaning solution for entertainment industry datasets, handling common issues like missing values, outliers, inconsistent formatting, and categorical encoding. The pipeline is built with scalability and reproducibility in mind.

## ğŸš€ Features

- **ğŸ” Smart Data Loading** - Handles various data formats and encoding issues
- **ğŸ§¹ Missing Value Imputation** - Intelligent handling of NaN values for both numeric and categorical columns
- **ğŸ“… Year Extraction** - Automatically extracts and cleans year information from multiple formats
- **ğŸ“Š Outlier Detection** - Statistical outlier removal using Interquartile Range (IQR)
- **ğŸ”¤ Categorical Encoding** - Label encoding for machine learning compatibility
- **âš–ï¸ Feature Scaling** - Standardization of numeric features
- **ğŸ”„ Duplicate Removal** - Automatic detection and removal of duplicate entries
- **ğŸ·ï¸ Column Standardization** - Clean and consistent column naming conventions

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.8+
- pip package manager

### Setup

1. **Clone the repository**
```bash
git clone https://github.com/AchrafElboumashouli/Data-Cleaning-Pipeline.git
cd Data-Cleaning-Pipeline
```

2. **Create virtual environment (recommended)**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

## ğŸ“ Project Structure

```
data-cleaning-pipeline/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_data.csv            # Example input data
â”‚   â””â”€â”€ cleaned_data.csv        # Output after cleaning
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ data_cleaning.py        # Main Python script
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ demo_data_cleaning.ipynb # Optional Jupyter Notebook
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

```

## ğŸ¯ Usage

### Basic Usage

```python
from data_cleaning_pipeline import main

# Run the complete cleaning pipeline
main()
```

### Custom Usage

```python
import pandas as pd
from data_cleaning_pipeline import load_data, handle_missing_values, remove_outliers

# Load your data
df = load_data("your_movie_data.csv")

# Apply specific cleaning steps
df = handle_missing_values(df)
df = remove_outliers(df)

# Save cleaned data
df.to_csv("cleaned_data.csv", index=False)
```

### Command Line Usage

```bash
python data_cleaning_pipeline.py
```

## ğŸ“ˆ Data Processing Steps

The pipeline performs the following transformations:

1. **Data Loading** - Reads CSV files with proper error handling
2. **Column Cleaning** - Standardizes column names and formats
3. **Missing Value Treatment** - 
   - Numeric columns: Median imputation
   - Categorical columns: Mode imputation or 'Unknown' placeholder
4. **Year Extraction** - Parses year information from various formats
5. **Duplicate Removal** - Eliminates identical rows
6. **Outlier Detection** - Removes statistical outliers using IQR method
7. **Categorical Encoding** - Converts text categories to numerical values
8. **Feature Scaling** - Standardizes numerical features

## ğŸ“Š Output Data

The cleaned dataset includes:
- Standardized column names
- Consistent data types
- No missing values
- Properly encoded categorical variables
- Scaled numerical features
- Outlier-free distributions

## ğŸ§ª Example

**Input (Raw Data):**
```csv
MOVIES,YEAR,RATING,VOTES,RunTime
Blood Red,-2021,6.1,"21,062",121
Rick and Morty,(2013-),9.2,"414,849",23
```

**Output (Cleaned Data):**
```csv
MOVIES,YEAR_CLEANED,RATING,VOTES,RUNTIME
Blood Red,2021,6.1,21062,121
Rick and Morty,2013,9.2,414849,23
```

## ğŸ§ª Terminal output :

![terminal](Image/1.png)

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ› Troubleshooting

### Common Issues

1. **File Not Found Error**
   - Ensure the input file exists in the correct directory
   - Check file path and permissions

2. **Memory Issues**
   - Use `chunksize` parameter for large datasets
   - Consider using Dask for big data

3. **Encoding Problems**
   - Specify encoding in `pd.read_csv()` if needed
   - Use `encoding='utf-8'` or `encoding='latin-1'`

### Getting Help

- Create an issue on GitHub
- Check existing issues for solutions
- Contact the maintainers


## ğŸ™ Acknowledgments

- Built with pandas, numpy, and scikit-learn
- Inspired by real-world data cleaning challenges in entertainment analytics
- Thanks to the open-source community for continuous improvements

---

**â­ Star this repo if you find it helpful!**
---
ğŸ‘¤ Author

ACHRAF EL BOUMASHOULI ğŸ§ªâ­
