{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP78lLx0I7Nj6Gnsjmxsm4W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"2oOcJWVvBRjM","executionInfo":{"status":"ok","timestamp":1761054396739,"user_tz":-60,"elapsed":1032,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","import os"]},{"cell_type":"code","source":["def load_data(path: str) -> pd.DataFrame:\n","    \"\"\"Load dataset from a CSV file.\"\"\"\n","    if not os.path.exists(path):\n","        raise FileNotFoundError(f\"❌ File not found: {path}\")\n","    print(\"📂 Loading data...\")\n","    df = pd.read_csv(path, low_memory=False)\n","    print(f\"✅ Data loaded successfully! Shape: {df.shape}\")\n","    return df"],"metadata":{"id":"CA2Kf9-SBaED","executionInfo":{"status":"ok","timestamp":1761054410804,"user_tz":-60,"elapsed":14,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def handle_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Handle missing values for numeric and categorical columns.\"\"\"\n","    print(\"🧩 Handling missing values...\")\n","    df.columns = df.columns.str.strip()\n","    df = df.dropna(axis=1, how='all')\n","\n","    # Identify numeric columns\n","    potential_num_cols = ['RATING', 'VOTES', 'RunTime', 'Gross']\n","    num_cols = [col for col in potential_num_cols if col in df.columns]\n","\n","    # Identify categorical columns\n","    cat_cols = ['MOVIES', 'YEAR', 'GENRE', 'ONE-LINE', 'STARS']\n","    cat_cols = [col for col in cat_cols if col in df.columns]\n","\n","    for col in num_cols:\n","        if col in df.columns:\n","            if col == 'VOTES':\n","                df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='coerce')\n","            else:\n","                df[col] = pd.to_numeric(df[col], errors='coerce')\n","\n","    for col in num_cols:\n","        if col in df.columns:\n","            df[col] = df[col].fillna(df[col].median())\n","\n","    for col in cat_cols:\n","        if col in df.columns:\n","            if df[col].isna().all():\n","                df[col] = 'Unknown'\n","            else:\n","                df[col] = df[col].fillna('Unknown')\n","\n","    print(\"✅ Missing values handled.\")\n","    return df"],"metadata":{"id":"Vb1Oz80FBaJb","executionInfo":{"status":"ok","timestamp":1761054418190,"user_tz":-60,"elapsed":4,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def remove_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Remove duplicate rows.\"\"\"\n","    print(\"🔁 Removing duplicates...\")\n","    before = df.shape[0]\n","    df = df.drop_duplicates()\n","    after = df.shape[0]\n","    print(f\"✅ Removed {before - after} duplicate rows.\")\n","    return df"],"metadata":{"id":"VqTgxiUMBaLy","executionInfo":{"status":"ok","timestamp":1761054425600,"user_tz":-60,"elapsed":42,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def remove_outliers(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Detect and remove outliers using IQR for numeric columns only.\"\"\"\n","    print(\"📉 Removing outliers...\")\n","\n","    numeric_cols = df.select_dtypes(include=[np.number]).columns\n","    before = df.shape[0]\n","\n","    if len(numeric_cols) > 0:\n","        mask = pd.Series([True] * len(df))\n","\n","        for col in numeric_cols:\n","            Q1 = df[col].quantile(0.25)\n","            Q3 = df[col].quantile(0.75)\n","            IQR = Q3 - Q1\n","\n","            if IQR > 0:\n","                col_mask = (df[col] >= Q1 - 1.5 * IQR) & (df[col] <= Q3 + 1.5 * IQR)\n","                mask = mask & col_mask\n","\n","        df = df[mask]\n","\n","    print(f\"✅ Removed {before - df.shape[0]} outlier rows.\")\n","    return df\n"],"metadata":{"id":"3w8Xddw4Bfia","executionInfo":{"status":"ok","timestamp":1761054432497,"user_tz":-60,"elapsed":6,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def extract_year_info(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Extract and clean year information from YEAR column.\"\"\"\n","    print(\"📅 Processing year information...\")\n","\n","    if 'YEAR' in df.columns:\n","        df['YEAR_CLEANED'] = df['YEAR'].astype(str).str.extract(r'(\\d{4})')\n","        df['YEAR_CLEANED'] = pd.to_numeric(df['YEAR_CLEANED'], errors='coerce')\n","\n","        missing_years = df['YEAR_CLEANED'].isna()\n","        if missing_years.any():\n","            df.loc[missing_years, 'YEAR_CLEANED'] = df.loc[missing_years, 'MOVIES'].astype(str).str.extract(r'\\((\\d{4})')\n","            df['YEAR_CLEANED'] = pd.to_numeric(df['YEAR_CLEANED'], errors='coerce')\n","\n","    print(\"✅ Year information processed.\")\n","    return df"],"metadata":{"id":"MftxZmq0BfWS","executionInfo":{"status":"ok","timestamp":1761054438652,"user_tz":-60,"elapsed":12,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def encode_categorical(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Encode categorical columns using LabelEncoder.\"\"\"\n","    print(\"🔠 Encoding categorical features...\")\n","\n","    cat_cols = df.select_dtypes(exclude=[np.number]).columns\n","    cat_cols = [col for col in cat_cols if col not in ['MOVIES']]\n","\n","    le = LabelEncoder()\n","    for col in cat_cols:\n","        if df[col].nunique() > 1:\n","            df[col] = le.fit_transform(df[col].astype(str))\n","        else:\n","            df = df.drop(columns=[col])\n","\n","    print(\"✅ Encoding completed.\")\n","    return df"],"metadata":{"id":"NZ5J9qU6BaN6","executionInfo":{"status":"ok","timestamp":1761054447739,"user_tz":-60,"elapsed":14,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def scale_features(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Scale numeric features using StandardScaler.\"\"\"\n","    print(\"📏 Scaling numeric features...\")\n","\n","    numeric_cols = df.select_dtypes(include=[np.number]).columns\n","\n","    cols_to_scale = [col for col in numeric_cols if not col.endswith('_ENCODED')]\n","\n","    if len(cols_to_scale) > 0:\n","        scaler = StandardScaler()\n","        df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n","\n","    print(\"✅ Scaling done.\")\n","    return df"],"metadata":{"id":"F2T-bfoZBaPy","executionInfo":{"status":"ok","timestamp":1761054453800,"user_tz":-60,"elapsed":9,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def clean_column_names(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Clean and standardize column names.\"\"\"\n","    print(\"🔄 Cleaning column names...\")\n","\n","    df.columns = (df.columns\n","                  .str.strip()\n","                  .str.upper()\n","                  .str.replace(' ', '_')\n","                  .str.replace('-', '_')\n","                  .str.replace(r'[^\\w_]', '', regex=True))\n","\n","    print(\"✅ Column names cleaned.\")\n","    return df"],"metadata":{"id":"1KMWZuqTBnx1","executionInfo":{"status":"ok","timestamp":1761054463357,"user_tz":-60,"elapsed":13,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def save_cleaned_data(df: pd.DataFrame, output_path: str):\n","    \"\"\"Save cleaned DataFrame to CSV.\"\"\"\n","    df.to_csv(output_path, index=False)\n","    print(f\"💾 Cleaned data saved to {output_path}\")"],"metadata":{"id":"KT0FVfB8Bn0i","executionInfo":{"status":"ok","timestamp":1761054469898,"user_tz":-60,"elapsed":3,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Phb22VThCIqc","executionInfo":{"status":"ok","timestamp":1761054644489,"user_tz":-60,"elapsed":18024,"user":{"displayName":"Achraf","userId":"04946329700988742089"}},"outputId":"4e661709-c5c5-42f0-b8ed-92c0adc1da4c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Main execution flow\n","def main():\n","    print(\"🚀 Starting Data Cleaning Pipeline...\")\n","    input_path = \"/content/drive/MyDrive/movies.csv\"\n","    output_path = \"cleaned_movies_data.csv\"\n","\n","    try:\n","        df = load_data(input_path)\n","        df = clean_column_names(df)\n","        df = handle_missing_values(df)\n","        df = extract_year_info(df)\n","        df = remove_duplicates(df)\n","        df = remove_outliers(df)\n","        df = encode_categorical(df)\n","        df = scale_features(df)\n","        save_cleaned_data(df, output_path)\n","\n","        print(f\"🏁 Data cleaning completed successfully!\")\n","        print(f\"📊 Final dataset shape: {df.shape}\")\n","        print(f\"📋 Columns: {list(df.columns)}\")\n","\n","    except Exception as e:\n","        print(f\"❌ Error during data cleaning: {e}\")\n","        raise\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qfi1n_fJBn3i","executionInfo":{"status":"ok","timestamp":1761054682125,"user_tz":-60,"elapsed":935,"user":{"displayName":"Achraf","userId":"04946329700988742089"}},"outputId":"4c36466b-27e6-4bf6-9e3c-b5839d03acf2"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["🚀 Starting Data Cleaning Pipeline...\n","📂 Loading data...\n","✅ Data loaded successfully! Shape: (9999, 9)\n","🔄 Cleaning column names...\n","✅ Column names cleaned.\n","🧩 Handling missing values...\n","✅ Missing values handled.\n","📅 Processing year information...\n","✅ Year information processed.\n","🔁 Removing duplicates...\n","✅ Removed 431 duplicate rows.\n","📉 Removing outliers...\n","✅ Removed 5052 outlier rows.\n","🔠 Encoding categorical features...\n","✅ Encoding completed.\n","📏 Scaling numeric features...\n","✅ Scaling done.\n","💾 Cleaned data saved to cleaned_movies_data.csv\n","🏁 Data cleaning completed successfully!\n","📊 Final dataset shape: (4516, 10)\n","📋 Columns: ['MOVIES', 'YEAR', 'GENRE', 'RATING', 'ONE_LINE', 'STARS', 'VOTES', 'RUNTIME', 'GROSS', 'YEAR_CLEANED']\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2547358360.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n","  df = df[mask]\n"]}]}]}