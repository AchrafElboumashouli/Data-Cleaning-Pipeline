{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP78lLx0I7Nj6Gnsjmxsm4W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"2oOcJWVvBRjM","executionInfo":{"status":"ok","timestamp":1761054396739,"user_tz":-60,"elapsed":1032,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","import os"]},{"cell_type":"code","source":["def load_data(path: str) -> pd.DataFrame:\n","    \"\"\"Load dataset from a CSV file.\"\"\"\n","    if not os.path.exists(path):\n","        raise FileNotFoundError(f\"âŒ File not found: {path}\")\n","    print(\"ğŸ“‚ Loading data...\")\n","    df = pd.read_csv(path, low_memory=False)\n","    print(f\"âœ… Data loaded successfully! Shape: {df.shape}\")\n","    return df"],"metadata":{"id":"CA2Kf9-SBaED","executionInfo":{"status":"ok","timestamp":1761054410804,"user_tz":-60,"elapsed":14,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def handle_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Handle missing values for numeric and categorical columns.\"\"\"\n","    print(\"ğŸ§© Handling missing values...\")\n","    df.columns = df.columns.str.strip()\n","    df = df.dropna(axis=1, how='all')\n","\n","    # Identify numeric columns\n","    potential_num_cols = ['RATING', 'VOTES', 'RunTime', 'Gross']\n","    num_cols = [col for col in potential_num_cols if col in df.columns]\n","\n","    # Identify categorical columns\n","    cat_cols = ['MOVIES', 'YEAR', 'GENRE', 'ONE-LINE', 'STARS']\n","    cat_cols = [col for col in cat_cols if col in df.columns]\n","\n","    for col in num_cols:\n","        if col in df.columns:\n","            if col == 'VOTES':\n","                df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='coerce')\n","            else:\n","                df[col] = pd.to_numeric(df[col], errors='coerce')\n","\n","    for col in num_cols:\n","        if col in df.columns:\n","            df[col] = df[col].fillna(df[col].median())\n","\n","    for col in cat_cols:\n","        if col in df.columns:\n","            if df[col].isna().all():\n","                df[col] = 'Unknown'\n","            else:\n","                df[col] = df[col].fillna('Unknown')\n","\n","    print(\"âœ… Missing values handled.\")\n","    return df"],"metadata":{"id":"Vb1Oz80FBaJb","executionInfo":{"status":"ok","timestamp":1761054418190,"user_tz":-60,"elapsed":4,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def remove_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Remove duplicate rows.\"\"\"\n","    print(\"ğŸ” Removing duplicates...\")\n","    before = df.shape[0]\n","    df = df.drop_duplicates()\n","    after = df.shape[0]\n","    print(f\"âœ… Removed {before - after} duplicate rows.\")\n","    return df"],"metadata":{"id":"VqTgxiUMBaLy","executionInfo":{"status":"ok","timestamp":1761054425600,"user_tz":-60,"elapsed":42,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def remove_outliers(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Detect and remove outliers using IQR for numeric columns only.\"\"\"\n","    print(\"ğŸ“‰ Removing outliers...\")\n","\n","    numeric_cols = df.select_dtypes(include=[np.number]).columns\n","    before = df.shape[0]\n","\n","    if len(numeric_cols) > 0:\n","        mask = pd.Series([True] * len(df))\n","\n","        for col in numeric_cols:\n","            Q1 = df[col].quantile(0.25)\n","            Q3 = df[col].quantile(0.75)\n","            IQR = Q3 - Q1\n","\n","            if IQR > 0:\n","                col_mask = (df[col] >= Q1 - 1.5 * IQR) & (df[col] <= Q3 + 1.5 * IQR)\n","                mask = mask & col_mask\n","\n","        df = df[mask]\n","\n","    print(f\"âœ… Removed {before - df.shape[0]} outlier rows.\")\n","    return df\n"],"metadata":{"id":"3w8Xddw4Bfia","executionInfo":{"status":"ok","timestamp":1761054432497,"user_tz":-60,"elapsed":6,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def extract_year_info(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Extract and clean year information from YEAR column.\"\"\"\n","    print(\"ğŸ“… Processing year information...\")\n","\n","    if 'YEAR' in df.columns:\n","        df['YEAR_CLEANED'] = df['YEAR'].astype(str).str.extract(r'(\\d{4})')\n","        df['YEAR_CLEANED'] = pd.to_numeric(df['YEAR_CLEANED'], errors='coerce')\n","\n","        missing_years = df['YEAR_CLEANED'].isna()\n","        if missing_years.any():\n","            df.loc[missing_years, 'YEAR_CLEANED'] = df.loc[missing_years, 'MOVIES'].astype(str).str.extract(r'\\((\\d{4})')\n","            df['YEAR_CLEANED'] = pd.to_numeric(df['YEAR_CLEANED'], errors='coerce')\n","\n","    print(\"âœ… Year information processed.\")\n","    return df"],"metadata":{"id":"MftxZmq0BfWS","executionInfo":{"status":"ok","timestamp":1761054438652,"user_tz":-60,"elapsed":12,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def encode_categorical(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Encode categorical columns using LabelEncoder.\"\"\"\n","    print(\"ğŸ”  Encoding categorical features...\")\n","\n","    cat_cols = df.select_dtypes(exclude=[np.number]).columns\n","    cat_cols = [col for col in cat_cols if col not in ['MOVIES']]\n","\n","    le = LabelEncoder()\n","    for col in cat_cols:\n","        if df[col].nunique() > 1:\n","            df[col] = le.fit_transform(df[col].astype(str))\n","        else:\n","            df = df.drop(columns=[col])\n","\n","    print(\"âœ… Encoding completed.\")\n","    return df"],"metadata":{"id":"NZ5J9qU6BaN6","executionInfo":{"status":"ok","timestamp":1761054447739,"user_tz":-60,"elapsed":14,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def scale_features(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Scale numeric features using StandardScaler.\"\"\"\n","    print(\"ğŸ“ Scaling numeric features...\")\n","\n","    numeric_cols = df.select_dtypes(include=[np.number]).columns\n","\n","    cols_to_scale = [col for col in numeric_cols if not col.endswith('_ENCODED')]\n","\n","    if len(cols_to_scale) > 0:\n","        scaler = StandardScaler()\n","        df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n","\n","    print(\"âœ… Scaling done.\")\n","    return df"],"metadata":{"id":"F2T-bfoZBaPy","executionInfo":{"status":"ok","timestamp":1761054453800,"user_tz":-60,"elapsed":9,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def clean_column_names(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Clean and standardize column names.\"\"\"\n","    print(\"ğŸ”„ Cleaning column names...\")\n","\n","    df.columns = (df.columns\n","                  .str.strip()\n","                  .str.upper()\n","                  .str.replace(' ', '_')\n","                  .str.replace('-', '_')\n","                  .str.replace(r'[^\\w_]', '', regex=True))\n","\n","    print(\"âœ… Column names cleaned.\")\n","    return df"],"metadata":{"id":"1KMWZuqTBnx1","executionInfo":{"status":"ok","timestamp":1761054463357,"user_tz":-60,"elapsed":13,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def save_cleaned_data(df: pd.DataFrame, output_path: str):\n","    \"\"\"Save cleaned DataFrame to CSV.\"\"\"\n","    df.to_csv(output_path, index=False)\n","    print(f\"ğŸ’¾ Cleaned data saved to {output_path}\")"],"metadata":{"id":"KT0FVfB8Bn0i","executionInfo":{"status":"ok","timestamp":1761054469898,"user_tz":-60,"elapsed":3,"user":{"displayName":"Achraf","userId":"04946329700988742089"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Phb22VThCIqc","executionInfo":{"status":"ok","timestamp":1761054644489,"user_tz":-60,"elapsed":18024,"user":{"displayName":"Achraf","userId":"04946329700988742089"}},"outputId":"4e661709-c5c5-42f0-b8ed-92c0adc1da4c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Main execution flow\n","def main():\n","    print(\"ğŸš€ Starting Data Cleaning Pipeline...\")\n","    input_path = \"/content/drive/MyDrive/movies.csv\"\n","    output_path = \"cleaned_movies_data.csv\"\n","\n","    try:\n","        df = load_data(input_path)\n","        df = clean_column_names(df)\n","        df = handle_missing_values(df)\n","        df = extract_year_info(df)\n","        df = remove_duplicates(df)\n","        df = remove_outliers(df)\n","        df = encode_categorical(df)\n","        df = scale_features(df)\n","        save_cleaned_data(df, output_path)\n","\n","        print(f\"ğŸ Data cleaning completed successfully!\")\n","        print(f\"ğŸ“Š Final dataset shape: {df.shape}\")\n","        print(f\"ğŸ“‹ Columns: {list(df.columns)}\")\n","\n","    except Exception as e:\n","        print(f\"âŒ Error during data cleaning: {e}\")\n","        raise\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qfi1n_fJBn3i","executionInfo":{"status":"ok","timestamp":1761054682125,"user_tz":-60,"elapsed":935,"user":{"displayName":"Achraf","userId":"04946329700988742089"}},"outputId":"4c36466b-27e6-4bf6-9e3c-b5839d03acf2"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸš€ Starting Data Cleaning Pipeline...\n","ğŸ“‚ Loading data...\n","âœ… Data loaded successfully! Shape: (9999, 9)\n","ğŸ”„ Cleaning column names...\n","âœ… Column names cleaned.\n","ğŸ§© Handling missing values...\n","âœ… Missing values handled.\n","ğŸ“… Processing year information...\n","âœ… Year information processed.\n","ğŸ” Removing duplicates...\n","âœ… Removed 431 duplicate rows.\n","ğŸ“‰ Removing outliers...\n","âœ… Removed 5052 outlier rows.\n","ğŸ”  Encoding categorical features...\n","âœ… Encoding completed.\n","ğŸ“ Scaling numeric features...\n","âœ… Scaling done.\n","ğŸ’¾ Cleaned data saved to cleaned_movies_data.csv\n","ğŸ Data cleaning completed successfully!\n","ğŸ“Š Final dataset shape: (4516, 10)\n","ğŸ“‹ Columns: ['MOVIES', 'YEAR', 'GENRE', 'RATING', 'ONE_LINE', 'STARS', 'VOTES', 'RUNTIME', 'GROSS', 'YEAR_CLEANED']\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2547358360.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n","  df = df[mask]\n"]}]}]}